{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d256800-fb19-4898-a6a2-1e1852e9cdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      " Index(['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName',\n",
      "       '2000-01-31', '2000-02-29', '2000-03-31', '2000-04-30', '2000-05-31',\n",
      "       ...\n",
      "       '2023-08-31', '2023-09-30', '2023-10-31', '2023-11-30', '2023-12-31',\n",
      "       '2024-01-31', '2024-02-29', '2024-03-31', '2024-04-30', '2024-05-31'],\n",
      "      dtype='object', length=298)\n",
      "\n",
      "Step 1: Replace Headers\n",
      "    regionid  sizerank    regionname regiontype  statename     2000-01-31  \\\n",
      "0         9         0    California      state        NaN  193143.064540   \n",
      "1        54         1         Texas      state        NaN  112639.074920   \n",
      "2        14         2       Florida      state        NaN  107596.267297   \n",
      "3        43         3      New York      state        NaN  153038.753578   \n",
      "4        47         4  Pennsylvania      state        NaN   99768.755364   \n",
      "\n",
      "      2000-02-29     2000-03-31     2000-04-30     2000-05-31  ...  \\\n",
      "0  193792.276029  194668.870513  196571.695764  198783.443474  ...   \n",
      "1  112700.285903  112729.974189  112877.319783  112972.743101  ...   \n",
      "2  107829.330827  108111.850284  108686.139673  109305.448893  ...   \n",
      "3  153583.721872  154108.341740  155236.656459  156404.058856  ...   \n",
      "4   99982.153176  100182.689797  100591.352959  101011.152350  ...   \n",
      "\n",
      "      2023-08-31     2023-09-30     2023-10-31     2023-11-30     2023-12-31  \\\n",
      "0  754894.503307  762683.202370  769016.350352  773548.400889  776433.842623   \n",
      "1  305916.194282  305954.875267  305720.102712  305221.854088  304606.414079   \n",
      "2  392801.788025  393981.671177  395050.730911  395988.066490  396824.615852   \n",
      "3  448735.842671  451376.386795  453248.231149  454811.416001  456523.209990   \n",
      "4  260066.182157  261413.546528  262325.803375  262873.941583  263323.113230   \n",
      "\n",
      "      2024-01-31     2024-02-29     2024-03-31     2024-04-30     2024-05-31  \n",
      "0  776980.687472  776823.474485  778348.351254  782320.199922  786937.908863  \n",
      "1  304404.166458  304668.742248  305553.028931  306420.755160  306756.391110  \n",
      "2  397534.156102  398265.861097  399134.789495  399818.770353  399943.993352  \n",
      "3  458337.466162  460578.012652  463592.272124  467276.749322  470663.329940  \n",
      "4  263839.839392  264685.818773  266033.271174  267732.834806  269246.365597  \n",
      "\n",
      "[5 rows x 298 columns]\n",
      "\n",
      "Step 3: Handle Missing Values\n",
      " regionid       0\n",
      "sizerank       0\n",
      "regionname     0\n",
      "regiontype     0\n",
      "statename     51\n",
      "              ..\n",
      "2024-01-31     0\n",
      "2024-02-29     0\n",
      "2024-03-31     0\n",
      "2024-04-30     0\n",
      "2024-05-31     0\n",
      "Length: 298, dtype: int64\n",
      "\n",
      "Step 4: Remove Duplicates\n",
      " 0\n",
      "\n",
      "Step 5: Detect and Handle Outliers\n",
      "         regionid   sizerank  statename     2000-01-31     2000-02-29  \\\n",
      "count  47.000000  47.000000        0.0      47.000000      47.000000   \n",
      "mean   34.574468  25.404255        NaN  122665.860125  122833.961552   \n",
      "std    17.124537  14.858257        NaN   26148.409582   26256.407570   \n",
      "min     3.000000   1.000000        NaN   74892.262898   74889.057107   \n",
      "25%    21.500000  12.500000        NaN  105999.659680  106133.260495   \n",
      "50%    36.000000  25.000000        NaN  124122.364976  124047.120092   \n",
      "75%    48.500000  37.500000        NaN  135190.890716  135542.728249   \n",
      "max    62.000000  51.000000        NaN  178509.080986  179142.916978   \n",
      "\n",
      "          2000-03-31     2000-04-30     2000-05-31     2000-06-30  \\\n",
      "count      47.000000      47.000000      47.000000      47.000000   \n",
      "mean   123045.065532  123483.411105  124026.811623  124610.436314   \n",
      "std     26373.843509   26616.483870   26890.526090   27165.848501   \n",
      "min     74913.264594   74974.535179   75094.071008   75292.647290   \n",
      "25%    106261.378599  106584.405073  106778.767727  106920.079791   \n",
      "50%    124094.794401  124193.776950  124516.541202  124911.013628   \n",
      "75%    135973.069094  136453.879152  137248.997759  138054.609336   \n",
      "max    179843.371323  181409.562055  183157.702445  185045.415592   \n",
      "\n",
      "          2000-07-31  ...     2023-08-31     2023-09-30     2023-10-31  \\\n",
      "count      47.000000  ...      47.000000      47.000000      47.000000   \n",
      "mean   125234.563281  ...  334485.776368  335797.056603  336783.824936   \n",
      "std     27442.806890  ...  107324.196467  108076.207485  108711.306609   \n",
      "min     75553.596846  ...  162084.065796  162191.824457  162140.621640   \n",
      "25%    107075.710257  ...  240153.733411  241108.698636  241782.577102   \n",
      "50%    125301.114013  ...  323974.808874  325466.069486  326686.890361   \n",
      "75%    138824.657879  ...  416541.290781  418150.416384  419512.608387   \n",
      "max    186958.155014  ...  583583.249454  585987.255011  587687.960588   \n",
      "\n",
      "          2023-11-30     2023-12-31     2024-01-31     2024-02-29  \\\n",
      "count      47.000000      47.000000      47.000000      47.000000   \n",
      "mean   337403.111266  337745.204757  338033.159791  338809.513690   \n",
      "std    109124.789334  109424.030297  109627.420838  109914.591431   \n",
      "min    162257.248650  162503.031726  162714.267570  163244.962975   \n",
      "25%    242101.645332  242243.360820  242499.965864  243307.610997   \n",
      "50%    327587.085395  328177.853713  328619.119157  329295.590967   \n",
      "75%    420502.851558  421465.201228  421651.035328  422438.768282   \n",
      "max    588590.121864  589104.328398  589574.788455  590687.206155   \n",
      "\n",
      "          2024-03-31     2024-04-30     2024-05-31  \n",
      "count      47.000000      47.000000      47.000000  \n",
      "mean   340462.381167  342573.085684  344274.223220  \n",
      "std    110339.627733  110830.525506  111218.952298  \n",
      "min    164541.440598  166246.673446  167861.824913  \n",
      "25%    244830.730189  246690.430563  248013.848278  \n",
      "50%    330618.620755  332267.121803  333613.908298  \n",
      "75%    424262.345239  426562.460821  428334.531515  \n",
      "max    593385.255176  596970.896753  600204.236861  \n",
      "\n",
      "[8 rows x 296 columns]\n",
      "\n",
      "Final Cleaned Data\n",
      "    regionid  sizerank    regionname regiontype  statename     2000-01-31  \\\n",
      "1        54         1         Texas      state        NaN  112639.074920   \n",
      "2        14         2       Florida      state        NaN  107596.267297   \n",
      "3        43         3      New York      state        NaN  153038.753578   \n",
      "4        47         4  Pennsylvania      state        NaN   99768.755364   \n",
      "5        21         5      Illinois      state        NaN  128503.852178   \n",
      "\n",
      "      2000-02-29     2000-03-31     2000-04-30     2000-05-31  ...  \\\n",
      "1  112700.285903  112729.974189  112877.319783  112972.743101  ...   \n",
      "2  107829.330827  108111.850284  108686.139673  109305.448893  ...   \n",
      "3  153583.721872  154108.341740  155236.656459  156404.058856  ...   \n",
      "4   99982.153176  100182.689797  100591.352959  101011.152350  ...   \n",
      "5  128606.836060  128829.440342  129353.113978  129974.469117  ...   \n",
      "\n",
      "      2023-08-31     2023-09-30     2023-10-31     2023-11-30     2023-12-31  \\\n",
      "1  305916.194282  305954.875267  305720.102712  305221.854088  304606.414079   \n",
      "2  392801.788025  393981.671177  395050.730911  395988.066490  396824.615852   \n",
      "3  448735.842671  451376.386795  453248.231149  454811.416001  456523.209990   \n",
      "4  260066.182157  261413.546528  262325.803375  262873.941583  263323.113230   \n",
      "5  253858.781497  255383.149647  256609.423548  257477.182491  258124.236275   \n",
      "\n",
      "      2024-01-31     2024-02-29     2024-03-31     2024-04-30     2024-05-31  \n",
      "1  304404.166458  304668.742248  305553.028931  306420.755160  306756.391110  \n",
      "2  397534.156102  398265.861097  399134.789495  399818.770353  399943.993352  \n",
      "3  458337.466162  460578.012652  463592.272124  467276.749322  470663.329940  \n",
      "4  263839.839392  264685.818773  266033.271174  267732.834806  269246.365597  \n",
      "5  258596.951908  259650.316821  261560.273709  264025.888971  265824.254502  \n",
      "\n",
      "[5 rows x 298 columns]\n",
      "\n",
      "Ethical Implications\n",
      " \n",
      "Ethical Implications of Data Wrangling:\n",
      "\n",
      "1. What changes were made to the data?\n",
      "   Headers were replaced for readability, missing values were filled with the median, data types were standardized, duplicates were removed, and outliers were handled.\n",
      "\n",
      "2. Are there any legal or regulatory guidelines for your data or project topic?\n",
      "   The data is sourced from Zillow, a public and reputable source. There are no specific legal restrictions on the use of this data for analysis, but it is important to ensure the data is used ethically and with respect to privacy.\n",
      "\n",
      "3. What risks could be created based on the transformations done?\n",
      "   Filling missing values with the median can introduce bias if the missing data is not randomly distributed. Removing outliers might lead to the loss of significant data points.\n",
      "\n",
      "4. Did you make any assumptions in cleaning/transforming the data?\n",
      "   Assumptions were made that the median is a suitable replacement for missing values and that detected outliers are not representative of typical data points.\n",
      "\n",
      "5. How was your data sourced / verified for credibility?\n",
      "   The data was sourced from Zillow, which is a reputable source for real estate data.\n",
      "\n",
      "6. Was your data acquired in an ethical way?\n",
      "   Yes, the data was acquired from a publicly available source with no restrictions on its use for analysis.\n",
      "\n",
      "7. How would you mitigate any of the ethical implications you have identified?\n",
      "   To mitigate ethical risks, it is important to document all assumptions and methods used in data cleaning. Additionally, sensitivity analysis can be conducted to understand the impact of these transformations on the results.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the CSV file\n",
    "url = 'https://files.zillowstatic.com/research/public_csvs/zhvi/State_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv?t=1719750545'\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Inspect the columns\n",
    "print(\"Columns in the dataset:\\n\", df.columns)\n",
    "\n",
    "# Step 1: Replace Headers\n",
    "# Description: Replacing headers to make them more readable and consistent.\n",
    "df.columns = [col.strip().replace(' ', '_').lower() for col in df.columns]\n",
    "print(\"\\nStep 1: Replace Headers\\n\", df.head())\n",
    "\n",
    "# Check if there is a 'date' column\n",
    "if 'date' in df.columns:\n",
    "    # Step 2: Convert Data Types\n",
    "    # Description: Ensuring that date columns are in datetime format.\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    print(\"\\nStep 2: Convert Data Types\\n\", df.dtypes)\n",
    "\n",
    "# Step 3: Handle Missing Values\n",
    "# Description: Handling missing values by filling them with the median of the column.\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "print(\"\\nStep 3: Handle Missing Values\\n\", df.isnull().sum())\n",
    "\n",
    "# Step 4: Remove Duplicates\n",
    "# Description: Removing duplicate rows to ensure data integrity.\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"\\nStep 4: Remove Duplicates\\n\", df.duplicated().sum())\n",
    "\n",
    "# Step 5: Detect and Handle Outliers\n",
    "# Description: Detecting and handling outliers using the IQR method.\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = df[numeric_cols].quantile(0.25)\n",
    "Q3 = df[numeric_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Applying the IQR method\n",
    "df_outliers_removed = df[~((df[numeric_cols] < (Q1 - 1.5 * IQR)) | (df[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(\"\\nStep 5: Detect and Handle Outliers\\n\", df_outliers_removed.describe())\n",
    "\n",
    "# Human readable dataset after all transformations\n",
    "print(\"\\nFinal Cleaned Data\\n\", df_outliers_removed.head())\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df_outliers_removed.to_csv('cleaned_output.csv', index=False)\n",
    "\n",
    "# Ethical Implications\n",
    "\n",
    "ethical_implications = \"\"\"\n",
    "Ethical Implications of Data Wrangling:\n",
    "\n",
    "1. What changes were made to the data?\n",
    "   Headers were replaced for readability, missing values were filled with the median, data types were standardized, duplicates were removed, and outliers were handled.\n",
    "\n",
    "2. Are there any legal or regulatory guidelines for your data or project topic?\n",
    "   The data is sourced from Zillow, a public and reputable source. There are no specific legal restrictions on the use of this data for analysis, but it is important to ensure the data is used ethically and with respect to privacy.\n",
    "\n",
    "3. What risks could be created based on the transformations done?\n",
    "   Filling missing values with the median can introduce bias if the missing data is not randomly distributed. Removing outliers might lead to the loss of significant data points.\n",
    "\n",
    "4. Did you make any assumptions in cleaning/transforming the data?\n",
    "   Assumptions were made that the median is a suitable replacement for missing values and that detected outliers are not representative of typical data points.\n",
    "\n",
    "5. How was your data sourced / verified for credibility?\n",
    "   The data was sourced from Zillow, which is a reputable source for real estate data.\n",
    "\n",
    "6. Was your data acquired in an ethical way?\n",
    "   Yes, the data was acquired from a publicly available source with no restrictions on its use for analysis.\n",
    "\n",
    "7. How would you mitigate any of the ethical implications you have identified?\n",
    "   To mitigate ethical risks, it is important to document all assumptions and methods used in data cleaning. Additionally, sensitivity analysis can be conducted to understand the impact of these transformations on the results.\n",
    "\n",
    "\"\"\"\n",
    "print(\"\\nEthical Implications\\n\", ethical_implications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae570f0c-5c6a-4fb9-a66b-41aa22f61bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
