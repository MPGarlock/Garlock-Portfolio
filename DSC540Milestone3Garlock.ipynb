{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d03a017-0a18-4389-a219-df2ae4cadae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milestone 3: Cleaning and Formatting Website Data\n",
    "# Matt Garlock\n",
    "# 7/8/24\n",
    "# DSC 540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3366bee0-a932-47cc-bb5a-701cce55527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the data from the website\n",
    "url = \"https://meric.mo.gov/data/cost-living-data-series\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Locate the table in the HTML content\n",
    "table = soup.find('table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12631b96-bd9e-4b65-864d-844d3495cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Replace Headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954d11ac-777a-4456-921d-42a849af6da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Replace Headers\n",
      "   rank          state index grocery housing utilities transportation health  \\\n",
      "0    1  West Virginia  83.8    99.6    57.4      94.5           92.8  101.3   \n",
      "1    2       Oklahoma  86.4    95.4    68.9      97.3           89.3   95.2   \n",
      "2    3         Kansas  87.3    95.6    74.5      96.2           87.2   98.6   \n",
      "3    4        Alabama  88.1    97.1    69.4     100.7           91.2   87.2   \n",
      "4    5    Mississippi  88.3    96.1    75.2      90.7           89.7  100.7   \n",
      "\n",
      "  misc.  \n",
      "0  90.9  \n",
      "1  92.0  \n",
      "2  90.5  \n",
      "3  95.6  \n",
      "4  93.2  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Replace Headers\n",
    "headers = [header.text.strip().replace(' ', '_').lower() for header in table.find_all('th')]\n",
    "\n",
    "# Extract rows and cells\n",
    "rows = []\n",
    "for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "    cells = row.find_all('td')\n",
    "    cells = [cell.text.strip() for cell in cells]\n",
    "    rows.append(cells)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "print(\"Step 2: Replace Headers\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e901014a-a077-43b7-97b4-78262e0f4e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Format Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a733a6-e956-4e26-b4f2-61c4f609b833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Format data into a more readable format\n",
      "   rank          state index grocery housing utilities transportation health  \\\n",
      "0    1  West Virginia  83.8    99.6    57.4      94.5           92.8  101.3   \n",
      "1    2       Oklahoma  86.4    95.4    68.9      97.3           89.3   95.2   \n",
      "2    3         Kansas  87.3    95.6    74.5      96.2           87.2   98.6   \n",
      "3    4        Alabama  88.1    97.1    69.4     100.7           91.2   87.2   \n",
      "4    5    Mississippi  88.3    96.1    75.2      90.7           89.7  100.7   \n",
      "\n",
      "  misc.  \n",
      "0  90.9  \n",
      "1  92.0  \n",
      "2  90.5  \n",
      "3  95.6  \n",
      "4  93.2  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Format data into a more readable format\n",
    "df.replace(\"\", pd.NA, inplace=True)\n",
    "df.dropna(how='all', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"\\nStep 3: Format data into a more readable format\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae709397-d16c-485f-9089-1864534e39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Identify and Handle Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1a08b3c-b675-4a1b-bbc9-7e4a23b25e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Identify and Handle Outliers\n",
      "        rank          state index grocery housing utilities transportation  \\\n",
      "count    53             53    53      53      53        53             53   \n",
      "unique   53             53    50      40      51        51             50   \n",
      "top       1  West Virginia  88.5    99.6    88.1      97.9          107.5   \n",
      "freq      1              1     2       3       2         2              2   \n",
      "\n",
      "       health misc.  \n",
      "count      53    53  \n",
      "unique     48    49  \n",
      "top     100.7  92.0  \n",
      "freq        2     2  \n"
     ]
    }
   ],
   "source": [
    "# Step 4: Identify and Handle Outliers\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = df[numeric_columns].quantile(0.25)\n",
    "Q3 = df[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df_outliers_removed = df[~((df[numeric_columns] < (Q1 - 1.5 * IQR)) | (df[numeric_columns] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(\"\\nStep 4: Identify and Handle Outliers\\n\", df_outliers_removed.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e739377-c03d-4253-9bae-6f701039f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Find and Remove Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "407769a7-8e14-4e18-811c-5efc24b7514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Find and Remove Duplicates\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Find and Remove Duplicates\n",
    "df_outliers_removed.drop_duplicates(inplace=True)\n",
    "print(\"\\nStep 5: Find and Remove Duplicates\\n\", df_outliers_removed.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c81b35-b813-4ca9-bac9-70809b239be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Fix Casing or Inconsistent Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee534db9-1a38-42e4-9410-ea2067824361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6: Fix Casing or Inconsistent Values\n",
      "   rank          state index grocery housing utilities transportation health  \\\n",
      "0    1  west virginia  83.8    99.6    57.4      94.5           92.8  101.3   \n",
      "1    2       oklahoma  86.4    95.4    68.9      97.3           89.3   95.2   \n",
      "2    3         kansas  87.3    95.6    74.5      96.2           87.2   98.6   \n",
      "3    4        alabama  88.1    97.1    69.4     100.7           91.2   87.2   \n",
      "4    5    mississippi  88.3    96.1    75.2      90.7           89.7  100.7   \n",
      "\n",
      "  misc.  \n",
      "0  90.9  \n",
      "1  92.0  \n",
      "2  90.5  \n",
      "3  95.6  \n",
      "4  93.2  \n"
     ]
    }
   ],
   "source": [
    "# Step 6: Fix Casing or Inconsistent Values\n",
    "df_outliers_removed = df_outliers_removed.apply(lambda col: col.map(lambda x: x.lower() if isinstance(x, str) else x))\n",
    "print(\"\\nStep 6: Fix Casing or Inconsistent Values\\n\", df_outliers_removed.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3ba65a9-a894-4847-aee1-63ca4826cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Cleaned Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6118a6b3-0539-4409-9b4a-f0be172edc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Cleaned Data\n",
      "    rank                 state  index grocery housing utilities transportation  \\\n",
      "0     1         west virginia   83.8    99.6    57.4      94.5           92.8   \n",
      "1     2              oklahoma   86.4    95.4    68.9      97.3           89.3   \n",
      "2     3                kansas   87.3    95.6    74.5      96.2           87.2   \n",
      "3     4               alabama   88.1    97.1    69.4     100.7           91.2   \n",
      "4     5           mississippi   88.3    96.1    75.2      90.7           89.7   \n",
      "5     6              missouri   88.5    95.5    77.7      98.5           84.0   \n",
      "6     7              arkansas   88.5    95.0    74.9      90.7           88.2   \n",
      "7     8                  iowa   90.1    96.7    75.1      93.5           96.9   \n",
      "8     9               indiana   90.3    97.6    77.8      90.4           94.8   \n",
      "9    10             tennessee   90.3    97.1    82.8      88.6           89.1   \n",
      "10   11               georgia   91.3    97.7    79.7      94.0           97.7   \n",
      "11   12              michigan   91.8    98.3    77.0      97.0           98.3   \n",
      "12   13             louisiana   92.1    95.8    84.6      79.7           95.4   \n",
      "13   14                 texas   92.4    96.2    82.1     103.6           92.7   \n",
      "14   15              kentucky   92.6    99.7    78.2      87.1           95.1   \n",
      "15   16          north dakota   92.8    94.5    82.2      83.4           98.7   \n",
      "16   17              illinois   93.3    97.7    82.2      98.0           97.5   \n",
      "17   18              nebraska   93.4    98.2    80.7      90.5           96.1   \n",
      "18   19          south dakota   93.4    97.6    88.1      85.6          102.5   \n",
      "19   20            new mexico   93.6    95.8    88.1      86.5           92.5   \n",
      "20   21                  ohio   94.0    99.1    84.0     101.8           96.2   \n",
      "21   22               montana   94.6    99.7    84.8      83.9          107.5   \n",
      "22   23             minnesota   94.8   102.3    81.5      96.7           94.2   \n",
      "23   24               wyoming   95.1   100.4    87.6      85.5           88.5   \n",
      "24   25          pennsylvania   95.6    98.4    85.8     103.5          107.5   \n",
      "25   26             wisconsin   97.0    98.2    91.0      97.9           92.6   \n",
      "26   27        south carolina   97.6    99.6    90.7     111.2           95.1   \n",
      "27   28        north carolina   98.5    98.4    92.9      98.8           96.2   \n",
      "28   29              delaware  100.9   101.9    97.0      97.9          103.3   \n",
      "29   30                 idaho  101.1   103.5   100.9      78.4          109.8   \n",
      "30   31              virginia  101.3    99.9   107.0      99.9           94.3   \n",
      "31   32              colorado  101.8   100.4   108.2      90.3           93.6   \n",
      "32   33           puerto rico  102.6   112.7   102.1     160.4           89.6   \n",
      "33   34                nevada  102.7   104.0   109.0     107.7          117.5   \n",
      "34   35                  utah  102.9    98.1   111.9      94.4           99.9   \n",
      "35   36               florida  103.1   104.7   108.4     105.9          101.1   \n",
      "36   37               arizona  110.5   102.0   128.5     101.1          104.9   \n",
      "37   38                 maine  111.3   100.7   121.9     110.9          111.0   \n",
      "38   39           connecticut  113.2   102.0   117.8     133.8          107.6   \n",
      "39   40          rhode island  113.4   101.4   115.4     141.9           99.1   \n",
      "40   41         new hampshire  113.6    99.6   116.5     103.7          112.3   \n",
      "41   42            new jersey  113.7   103.5   135.6     100.1          106.9   \n",
      "42   43                oregon  114.1   108.5   135.0      89.1          121.3   \n",
      "43   44               vermont  114.7   105.8   128.8     112.6          100.8   \n",
      "44   45            washington  115.1   108.3   127.2      91.3          127.1   \n",
      "45   46              maryland  116.2   105.1   141.6     109.5          104.7   \n",
      "46   47              new york  123.1   103.3   166.2     102.3          109.9   \n",
      "47   48                alaska  125.1   126.5   120.8     148.9          117.0   \n",
      "48   49         massachusetts  144.3   104.0   212.8     149.0          113.8   \n",
      "49   50  district of columbia  144.6   105.2   235.0     107.9          106.8   \n",
      "50   51            california  145.0   112.3   209.7     135.8          141.3   \n",
      "51   52                hawaii  186.2   124.1   313.2     176.4          138.8   \n",
      "52   us                   ***  100.0   100.0   100.0     100.0          100.0   \n",
      "\n",
      "   health  misc.  \n",
      "0   101.3   90.9  \n",
      "1    95.2   92.0  \n",
      "2    98.6   90.5  \n",
      "3    87.2   95.6  \n",
      "4   100.7   93.2  \n",
      "5    91.2   93.0  \n",
      "6    88.2   96.7  \n",
      "7    96.3   95.7  \n",
      "8    97.3   95.1  \n",
      "9    90.2   94.5  \n",
      "10   99.9   94.4  \n",
      "11   90.9   98.0  \n",
      "12   94.5   98.8  \n",
      "13   96.1   96.0  \n",
      "14  106.8  100.3  \n",
      "15  109.3   99.3  \n",
      "16   99.9   97.1  \n",
      "17  102.4  100.8  \n",
      "18  102.0   94.0  \n",
      "19  101.0   98.4  \n",
      "20   94.6   97.4  \n",
      "21  108.9   97.1  \n",
      "22  106.3  100.8  \n",
      "23  105.9  102.1  \n",
      "24   88.4   97.8  \n",
      "25  109.6  100.9  \n",
      "26   92.9  100.5  \n",
      "27  105.0  102.9  \n",
      "28  101.7  103.6  \n",
      "29   97.5  103.8  \n",
      "30  102.0   99.6  \n",
      "31  105.5  102.1  \n",
      "32   69.6   92.0  \n",
      "33   90.6   92.3  \n",
      "34   89.5  102.3  \n",
      "35  100.6   98.3  \n",
      "36   93.6  105.6  \n",
      "37  114.9  106.7  \n",
      "38  107.4  111.4  \n",
      "39  105.2  115.4  \n",
      "40  103.5  121.7  \n",
      "41  105.0  106.6  \n",
      "42  112.4  103.5  \n",
      "43  109.8  112.5  \n",
      "44  117.9  109.8  \n",
      "45  100.7  107.2  \n",
      "46  105.7  107.8  \n",
      "47  153.1  120.6  \n",
      "48  123.6  116.1  \n",
      "49  116.0  111.8  \n",
      "50  105.7  114.1  \n",
      "51  122.0  133.5  \n",
      "52  100.0  100.0  \n"
     ]
    }
   ],
   "source": [
    "# Final Human Readable Data\n",
    "print(\"\\nFinal Cleaned Data\\n\", df_outliers_removed)\n",
    "\n",
    "# Save to a new HTML file to maintain format\n",
    "df_outliers_removed.to_html('cleaned_data.html', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87cabd69-9672-48d0-b52d-938895937e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethical Implications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f9b63a9-7ea7-43de-a752-aa0b1cb4ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ethical Implications\n",
      " \n",
      "Ethical Implications of Data Wrangling:\n",
      "\n",
      "1. What changes were made to the data?\n",
      "   Headers were replaced, data was formatted for readability, outliers were handled, duplicates were removed, and inconsistencies in casing were fixed.\n",
      "\n",
      "2. Are there any legal or regulatory guidelines for your data or project topic?\n",
      "   The data is sourced from a public website, ensuring no legal restrictions. However, ensuring accuracy and ethical use of the data is important.\n",
      "\n",
      "3. What risks could be created based on the transformations done?\n",
      "   Handling outliers and filling missing values can introduce bias. Removing duplicates might inadvertently remove legitimate repeated entries.\n",
      "\n",
      "4. Did you make any assumptions in cleaning/transforming the data?\n",
      "   Assumed that median is a suitable replacement for missing values and that outliers do not represent typical data points.\n",
      "\n",
      "5. How was your data sourced / verified for credibility?\n",
      "   Data was sourced from a credible public domain (MERIC website).\n",
      "\n",
      "6. Was your data acquired in an ethical way?\n",
      "   Yes, the data was acquired from a publicly available source.\n",
      "\n",
      "7. How would you mitigate any of the ethical implications you have identified?\n",
      "   Documenting assumptions and methods used in data cleaning. Conducting sensitivity analysis to understand the impact of transformations on results.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ethical Implications\n",
    "ethical_implications = \"\"\"\n",
    "Ethical Implications of Data Wrangling:\n",
    "\n",
    "1. What changes were made to the data?\n",
    "   Headers were replaced, data was formatted for readability, outliers were handled, duplicates were removed, and inconsistencies in casing were fixed.\n",
    "\n",
    "2. Are there any legal or regulatory guidelines for your data or project topic?\n",
    "   The data is sourced from a public website, ensuring no legal restrictions. However, ensuring accuracy and ethical use of the data is important.\n",
    "\n",
    "3. What risks could be created based on the transformations done?\n",
    "   Handling outliers and filling missing values can introduce bias. Removing duplicates might inadvertently remove legitimate repeated entries.\n",
    "\n",
    "4. Did you make any assumptions in cleaning/transforming the data?\n",
    "   Assumed that median is a suitable replacement for missing values and that outliers do not represent typical data points.\n",
    "\n",
    "5. How was your data sourced / verified for credibility?\n",
    "   Data was sourced from a credible public domain (MERIC website).\n",
    "\n",
    "6. Was your data acquired in an ethical way?\n",
    "   Yes, the data was acquired from a publicly available source.\n",
    "\n",
    "7. How would you mitigate any of the ethical implications you have identified?\n",
    "   Documenting assumptions and methods used in data cleaning. Conducting sensitivity analysis to understand the impact of transformations on results.\n",
    "\"\"\"\n",
    "print(\"\\nEthical Implications\\n\", ethical_implications)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7626a2f-a81f-4ca4-bcc5-272916354947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
