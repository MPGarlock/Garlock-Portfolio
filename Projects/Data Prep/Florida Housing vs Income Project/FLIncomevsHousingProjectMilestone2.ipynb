{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d256800-fb19-4898-a6a2-1e1852e9cdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      " Index(['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName',\n",
      "       '2000-01-31', '2000-02-29', '2000-03-31', '2000-04-30', '2000-05-31',\n",
      "       ...\n",
      "       '2024-03-31', '2024-04-30', '2024-05-31', '2024-06-30', '2024-07-31',\n",
      "       '2024-08-31', '2024-09-30', '2024-10-31', '2024-11-30', '2024-12-31'],\n",
      "      dtype='object', length=305)\n",
      "\n",
      "Step 1: Replace Headers\n",
      "    regionid  sizerank    regionname regiontype  statename     2000-01-31  \\\n",
      "0         9         0    California      state        NaN  186449.090913   \n",
      "1        54         1         Texas      state        NaN  111018.278532   \n",
      "2        14         2       Florida      state        NaN  105939.099867   \n",
      "3        43         3      New York      state        NaN  150532.342593   \n",
      "4        47         4  Pennsylvania      state        NaN   96695.081059   \n",
      "\n",
      "      2000-02-29     2000-03-31     2000-04-30     2000-05-31  ...  \\\n",
      "0  187075.801959  187922.015335  189758.892258  191893.984972  ...   \n",
      "1  111078.608733  111107.869825  111253.095221  111347.145464  ...   \n",
      "2  106168.573819  106446.741990  107012.186335  107621.957129  ...   \n",
      "3  151068.385602  151584.413444  152694.249050  153842.532171  ...   \n",
      "4   96901.904515   97096.263006   97492.336079   97899.202297  ...   \n",
      "\n",
      "      2024-03-31     2024-04-30     2024-05-31     2024-06-30     2024-07-31  \\\n",
      "0  751372.268275  755206.460175  759664.128050  762119.285892  764101.946106   \n",
      "1  301156.337588  302011.577853  302342.384240  302111.162485  301551.552917   \n",
      "2  392987.427789  393660.874166  393784.168515  393005.922425  391959.813824   \n",
      "3  455999.732745  459623.866964  462954.983442  465633.483093  468137.717390   \n",
      "4  257837.322182  259484.525684  260951.427641  261824.643030  262157.675704   \n",
      "\n",
      "      2024-08-31     2024-09-30     2024-10-31     2024-11-30     2024-12-31  \n",
      "0  765858.902416  768139.817461  769719.909003  771481.431234  773263.451715  \n",
      "1  301137.192876  300878.663198  300621.323932  300253.315889  299982.139510  \n",
      "2  390953.772856  390106.033410  389166.535852  387976.633622  386892.197619  \n",
      "3  471201.874589  474034.562219  476427.532571  478239.595605  479975.705663  \n",
      "4  262404.295100  262785.747263  263518.744987  264393.449200  265564.886725  \n",
      "\n",
      "[5 rows x 305 columns]\n",
      "\n",
      "Step 3: Handle Missing Values\n",
      " regionid       0\n",
      "sizerank       0\n",
      "regionname     0\n",
      "regiontype     0\n",
      "statename     51\n",
      "              ..\n",
      "2024-08-31     0\n",
      "2024-09-30     0\n",
      "2024-10-31     0\n",
      "2024-11-30     0\n",
      "2024-12-31     0\n",
      "Length: 305, dtype: int64\n",
      "\n",
      "Step 4: Remove Duplicates\n",
      " 0\n",
      "\n",
      "Step 5: Detect and Handle Outliers\n",
      "         regionid   sizerank  statename     2000-01-31     2000-02-29  \\\n",
      "count  47.000000  47.000000        0.0      47.000000      47.000000   \n",
      "mean   34.574468  25.404255        NaN  119404.319182  119568.134156   \n",
      "std    17.124537  14.858257        NaN   25683.181556   25788.548271   \n",
      "min     3.000000   1.000000        NaN   72199.778733   72196.688195   \n",
      "25%    21.500000  12.500000        NaN  103163.002732  103293.926472   \n",
      "50%    36.000000  25.000000        NaN  120253.802754  120180.903051   \n",
      "75%    48.500000  37.500000        NaN  132154.568431  132497.274713   \n",
      "max    62.000000  51.000000        NaN  174451.455000  175070.883494   \n",
      "\n",
      "          2000-03-31     2000-04-30     2000-05-31     2000-06-30  \\\n",
      "count      47.000000      47.000000      47.000000      47.000000   \n",
      "mean   119773.706792  120200.681892  120729.891328  121298.127838   \n",
      "std     25902.763917   26139.217962   26406.845031   26675.751971   \n",
      "min     72220.025388   72279.093207   72394.331551   72585.768732   \n",
      "25%    103419.005997  103733.833779  104132.881116  104600.081531   \n",
      "50%    120227.091480  120322.989007  120635.693561  121017.871336   \n",
      "75%    132917.700080  133633.276651  134428.939543  135212.004223   \n",
      "max    175755.416061  177286.006273  178994.410310  180839.214525   \n",
      "\n",
      "          2000-07-31  ...     2024-03-31     2024-04-30     2024-05-31  \\\n",
      "count      47.000000  ...      47.000000      47.000000      47.000000   \n",
      "mean   121905.635371  ...  331597.982640  333651.640212  335306.876356   \n",
      "std     26946.213337  ...  107601.725183  108076.978363  108453.804358   \n",
      "min     72837.336778  ...  158625.940035  160269.867318  161826.951775   \n",
      "25%    104839.166947  ...  235821.535426  237610.306271  238883.174912   \n",
      "50%    121395.813335  ...  322767.096787  324376.449267  325691.252304   \n",
      "75%    136178.421853  ...  416683.461233  419442.112105  421819.586766   \n",
      "max    182708.476153  ...  571927.656809  575383.636827  578500.055066   \n",
      "\n",
      "          2024-06-30     2024-07-31     2024-08-31     2024-09-30  \\\n",
      "count      47.000000      47.000000      47.000000      47.000000   \n",
      "mean   336151.393238  336556.100089  337038.709346  337706.720230   \n",
      "std    108601.028673  108735.723865  109019.091436  109550.813154   \n",
      "min    162937.487770  163869.993001  164439.921059  164746.891544   \n",
      "25%    239651.543128  240031.830602  240475.310377  240890.347592   \n",
      "50%    326029.398149  325684.155507  325859.679439  326484.262146   \n",
      "75%    422576.956810  422269.617579  421769.550039  421769.090740   \n",
      "max    579824.172034  580365.751853  580869.161629  582464.919668   \n",
      "\n",
      "          2024-10-31     2024-11-30     2024-12-31  \n",
      "count      47.000000      47.000000      47.000000  \n",
      "mean   338567.504733  339380.814761  340428.048358  \n",
      "std    110071.791937  110454.457995  110601.099114  \n",
      "min    165126.536920  165587.754654  166629.367184  \n",
      "25%    241470.719727  242161.344340  243197.574725  \n",
      "50%    326543.901135  325966.969051  325539.801900  \n",
      "75%    422178.324558  422657.751062  423133.856091  \n",
      "max    584626.110582  586964.436243  589180.394040  \n",
      "\n",
      "[8 rows x 303 columns]\n",
      "\n",
      "Final Cleaned Data\n",
      "    regionid  sizerank    regionname regiontype  statename     2000-01-31  \\\n",
      "1        54         1         Texas      state        NaN  111018.278532   \n",
      "2        14         2       Florida      state        NaN  105939.099867   \n",
      "3        43         3      New York      state        NaN  150532.342593   \n",
      "4        47         4  Pennsylvania      state        NaN   96695.081059   \n",
      "5        21         5      Illinois      state        NaN  124828.381038   \n",
      "\n",
      "      2000-02-29     2000-03-31     2000-04-30     2000-05-31  ...  \\\n",
      "1  111078.608733  111107.869825  111253.095221  111347.145464  ...   \n",
      "2  106168.573819  106446.741990  107012.186335  107621.957129  ...   \n",
      "3  151068.385602  151584.413444  152694.249050  153842.532171  ...   \n",
      "4   96901.904515   97096.263006   97492.336079   97899.202297  ...   \n",
      "5  124928.419372  125144.656720  125653.352226  126256.935346  ...   \n",
      "\n",
      "      2024-03-31     2024-04-30     2024-05-31     2024-06-30     2024-07-31  \\\n",
      "1  301156.337588  302011.577853  302342.384240  302111.162485  301551.552917   \n",
      "2  392987.427789  393660.874166  393784.168515  393005.922425  391959.813824   \n",
      "3  455999.732745  459623.866964  462954.983442  465633.483093  468137.717390   \n",
      "4  257837.322182  259484.525684  260951.427641  261824.643030  262157.675704   \n",
      "5  254079.118701  256474.212359  258221.140984  259322.797252  259954.121403   \n",
      "\n",
      "      2024-08-31     2024-09-30     2024-10-31     2024-11-30     2024-12-31  \n",
      "1  301137.192876  300878.663198  300621.323932  300253.315889  299982.139510  \n",
      "2  390953.772856  390106.033410  389166.535852  387976.633622  386892.197619  \n",
      "3  471201.874589  474034.562219  476427.532571  478239.595605  479975.705663  \n",
      "4  262404.295100  262785.747263  263518.744987  264393.449200  265564.886725  \n",
      "5  260753.726099  261516.006549  262371.134191  263290.240157  264399.140053  \n",
      "\n",
      "[5 rows x 305 columns]\n",
      "\n",
      "Ethical Implications\n",
      " \n",
      "Ethical Implications of Data Wrangling:\n",
      "\n",
      "1. What changes were made to the data?\n",
      "   Headers were replaced for readability, missing values were filled with the median, data types were standardized, duplicates were removed, and outliers were handled.\n",
      "\n",
      "2. Are there any legal or regulatory guidelines for your data or project topic?\n",
      "   The data is sourced from Zillow, a public and reputable source. There are no specific legal restrictions on the use of this data for analysis, but it is important to ensure the data is used ethically and with respect to privacy.\n",
      "\n",
      "3. What risks could be created based on the transformations done?\n",
      "   Filling missing values with the median can introduce bias if the missing data is not randomly distributed. Removing outliers might lead to the loss of significant data points.\n",
      "\n",
      "4. Did you make any assumptions in cleaning/transforming the data?\n",
      "   Assumptions were made that the median is a suitable replacement for missing values and that detected outliers are not representative of typical data points.\n",
      "\n",
      "5. How was your data sourced / verified for credibility?\n",
      "   The data was sourced from Zillow, which is a reputable source for real estate data.\n",
      "\n",
      "6. Was your data acquired in an ethical way?\n",
      "   Yes, the data was acquired from a publicly available source with no restrictions on its use for analysis.\n",
      "\n",
      "7. How would you mitigate any of the ethical implications you have identified?\n",
      "   To mitigate ethical risks, it is important to document all assumptions and methods used in data cleaning. Additionally, sensitivity analysis can be conducted to understand the impact of these transformations on the results.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the CSV file\n",
    "url = 'https://files.zillowstatic.com/research/public_csvs/zhvi/State_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv?t=1719750545'\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Inspect the columns\n",
    "print(\"Columns in the dataset:\\n\", df.columns)\n",
    "\n",
    "# Step 1: Replace Headers\n",
    "# Description: Replacing headers to make them more readable and consistent.\n",
    "df.columns = [col.strip().replace(' ', '_').lower() for col in df.columns]\n",
    "print(\"\\nStep 1: Replace Headers\\n\", df.head())\n",
    "\n",
    "# Check if there is a 'date' column\n",
    "if 'date' in df.columns:\n",
    "    # Step 2: Convert Data Types\n",
    "    # Description: Ensuring that date columns are in datetime format.\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    print(\"\\nStep 2: Convert Data Types\\n\", df.dtypes)\n",
    "\n",
    "# Step 3: Handle Missing Values\n",
    "# Description: Handling missing values by filling them with the median of the column.\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "print(\"\\nStep 3: Handle Missing Values\\n\", df.isnull().sum())\n",
    "\n",
    "# Step 4: Remove Duplicates\n",
    "# Description: Removing duplicate rows to ensure data integrity.\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"\\nStep 4: Remove Duplicates\\n\", df.duplicated().sum())\n",
    "\n",
    "# Step 5: Detect and Handle Outliers\n",
    "# Description: Detecting and handling outliers using the IQR method.\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "Q1 = df[numeric_cols].quantile(0.25)\n",
    "Q3 = df[numeric_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Applying the IQR method\n",
    "df_outliers_removed = df[~((df[numeric_cols] < (Q1 - 1.5 * IQR)) | (df[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(\"\\nStep 5: Detect and Handle Outliers\\n\", df_outliers_removed.describe())\n",
    "\n",
    "# Human readable dataset after all transformations\n",
    "print(\"\\nFinal Cleaned Data\\n\", df_outliers_removed.head())\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df_outliers_removed.to_csv('cleaned_output.csv', index=False)\n",
    "\n",
    "# Ethical Implications\n",
    "\n",
    "ethical_implications = \"\"\"\n",
    "Ethical Implications of Data Wrangling:\n",
    "\n",
    "1. What changes were made to the data?\n",
    "   Headers were replaced for readability, missing values were filled with the median, data types were standardized, duplicates were removed, and outliers were handled.\n",
    "\n",
    "2. Are there any legal or regulatory guidelines for your data or project topic?\n",
    "   The data is sourced from Zillow, a public and reputable source. There are no specific legal restrictions on the use of this data for analysis, but it is important to ensure the data is used ethically and with respect to privacy.\n",
    "\n",
    "3. What risks could be created based on the transformations done?\n",
    "   Filling missing values with the median can introduce bias if the missing data is not randomly distributed. Removing outliers might lead to the loss of significant data points.\n",
    "\n",
    "4. Did you make any assumptions in cleaning/transforming the data?\n",
    "   Assumptions were made that the median is a suitable replacement for missing values and that detected outliers are not representative of typical data points.\n",
    "\n",
    "5. How was your data sourced / verified for credibility?\n",
    "   The data was sourced from Zillow, which is a reputable source for real estate data.\n",
    "\n",
    "6. Was your data acquired in an ethical way?\n",
    "   Yes, the data was acquired from a publicly available source with no restrictions on its use for analysis.\n",
    "\n",
    "7. How would you mitigate any of the ethical implications you have identified?\n",
    "   To mitigate ethical risks, it is important to document all assumptions and methods used in data cleaning. Additionally, sensitivity analysis can be conducted to understand the impact of these transformations on the results.\n",
    "\n",
    "\"\"\"\n",
    "print(\"\\nEthical Implications\\n\", ethical_implications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae570f0c-5c6a-4fb9-a66b-41aa22f61bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv('/Users/mattgarlock/Downloads/cleaned_output_milestone2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffcae78-3490-41f7-90e3-21436c14e679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeaf64c-bfaa-4168-8fe5-e6f2402e6fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
